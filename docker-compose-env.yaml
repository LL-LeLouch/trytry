version: '3'

######## 项目依赖的环境，启动项目之前要先启动此环境 #######

services:

  etcd:                                  # 自定义容器名称
    image: bitnami/etcd
    container_name: etcd
    environment:
      - TZ=${TZ}
      - ALLOW_NONE_AUTHENTICATION=yes
    ports:                               # 设置端口映射
      - "${ETCD_PORT}:2379"
    networks:
      - backend
    restart: always
    
  #jaeger链路追踪
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    restart: always
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"
      - "14268:14268"
      - "9411:9411"
    environment:
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://elasticsearch:9200
      - LOG_LEVEL=debug
    networks:
      - backend

  #prometheus监控
  prometheus:
    image: prom/prometheus:v2.28.1
    container_name: prometheus
    environment:
      # 时区上海
      TZ: ${TZ}
    volumes:
      - ./deploy/prometheus/server/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./data/prometheus/data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    restart: always
    user: root
    ports:
      - "9090:9090"
    networks:
      - backend

  #查看prometheus监控数据
  grafana:
    image: grafana/grafana:8.0.6
    container_name: grafana
    hostname: grafana
    user: root
    environment:
      # 时区上海
      TZ: ${TZ}
    restart: always
    volumes:
        - ./data/grafana/data:/var/lib/grafana
    ports:
        - "3001:3000"
    networks:
        - backend

#  #搜集kafka业务日志、存储prometheus监控数据
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.13.4
    container_name: elasticsearch
    user: root
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - TZ=${TZ}
    volumes:
      - ./data/elasticsearch/data:/usr/share/elasticsearch/data
    restart: always
    ports:
    - 9200:9200
    - 9300:9300
    networks:
      - backend

  #查看elasticsearch数据
  kibana:
    image: docker.elastic.co/kibana/kibana:7.13.4
    container_name: kibana
    environment:
      - elasticsearch.hosts=http://elasticsearch:9200
      - TZ=${TZ}
    restart: always
    networks:
      - backend
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  #消费kafka中filebeat收集的数据输出到es
  go-stash:
    image: kevinwan/go-stash:1.0 # if you "macOs intel" or "linux amd"
#    image: kevinwan/go-stash:1.0-arm64 #  if you "macOs m1" or "linux arm"
    container_name: go-stash
    environment:
      # 时区上海
      TZ: ${TZ}
    user: root
    restart: always
    volumes:
      - ./deploy/go-stash/etc:/app/etc
    networks:
      - backend
    depends_on:
      - elasticsearch
      - kafka

  #收集业务数据
  filebeat:
    image: elastic/filebeat:7.13.4
    container_name: filebeat
    environment:
      # 时区上海
      TZ: ${TZ}
    user: root
    restart: always
    entrypoint: "filebeat -e -strict.perms=false"  #解决配置文件权限问题
    volumes:
      - ./deploy/filebeat/conf/filebeat.yml:/usr/share/filebeat/filebeat.yml
      # 此处需指定docker的containers目录，取决于你docker的配置
      # 如snap安装的docker，则为/var/snap/docker/common/var-lib-docker/containers
      # - /var/snap/docker/common/var-lib-docker/containers:/var/lib/docker/containers
      - /var/lib/docker/containers:/var/lib/docker/containers
    networks:
      - backend
    depends_on:
      - kafka


  #zookeeper是kafka的依赖
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    environment:
      # 时区上海
      TZ: ${TZ}
    restart: always
    ports:
      - "${ZOOKEEPER_PORT}:2181"
    networks:
      - backend

  #消息队列
  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ADVERTISED_HOST_NAME=kafka
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:${ZOOKEEPER_PORT}
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
      - TZ=${TZ}
    restart: always
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - backend
    depends_on:
      - zookeeper

  #asynqmon asynq延迟队列、定时队列的webui
  asynqmon:
    image: hibiken/asynqmon:latest
    container_name: asynqmon
    ports:
      - "${ASYNQMON_PORT}:8080"
    command:
      - '--redis-addr=redis:6379'
      - '--redis-password=${REDIS_PASS}'
    restart: always
    networks:
      - backend
    depends_on:
      - redis

  mysql:
    image: mysql:5.7
    container_name: mysql
    environment:
      - TZ=${TZ}
      - MYSQL_USER=${MYSQL_USERNAME}                  # 设置 Mysql 用户名称
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}              # 设置 Mysql 用户密码
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}    # 设置 Mysql root 用户密码
    ports:
      - "${MYSQL_PORT}:3306"
    volumes:
      # 数据挂载
      - ./data/mysql/data:/var/lib/mysql
      # 日志
    privileged: true
    restart: always
    networks:
      - backend
      
  #redis容器
  redis:
    image: redis
    container_name: redis
    ports:
      - "${REDIS_PORT}:6379"
    environment:
      # 时区上海
      TZ: ${TZ}
    volumes:
      # 数据文件
      - ./data/redis/data:/data:rw
    command: "redis-server --requirepass ${REDIS_PASS}  --appendonly yes"
    privileged: true
    restart: always
    networks:
      - backend
      
  dtm:
    image: yedf/dtm
    container_name: dtm
    environment:
      - TZ=${TZ}
    entrypoint:
      - "/app/dtm/dtm"
      - "-c=/app/dtm/configs/config.yaml"
    volumes:
      - ./deploy/dtm:/app/dtm/configs/ # 将 dtm 配置文件挂载到容器里
    ports:
      - "${DTM_HTTP_PORT}:36789"
      - "${DTM_GRPC_PORT}:36790"
    networks:
      - backend
    restart: always    
  


networks:
  backend:
    driver: ${NETWORKS_DRIVER}

